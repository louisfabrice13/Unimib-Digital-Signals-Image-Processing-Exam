{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UANCra3gx7y0"
   },
   "source": [
    "# Compito Esercitazione 6\n",
    "* Import E6\n",
    "* Data Loader E6\n",
    "* **ResNet50 vs InceptionV3 Fine Tuning**\n",
    "* **Data Augmentation**\n",
    "* **Relazione**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCq7z5iR06Ma"
   },
   "source": [
    "# Import E6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "T03GfCjcxxgC",
    "outputId": "6d151a4f-b786-4040-861c-8418adba4185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |▉                               | 10kB 21.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 20kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 30kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 40kB 6.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 51kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 61kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 71kB 6.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 81kB 6.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 92kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 102kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 112kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 122kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 133kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 143kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 153kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 163kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 174kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 184kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 194kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 204kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 215kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 225kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 235kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 245kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 256kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 266kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 276kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 286kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 296kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 307kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 317kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 327kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 337kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 348kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 358kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 368kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 378kB 6.7MB/s \n",
      "\u001b[?25h\u001b[?25l\r",
      "\u001b[K     |██████▌                         | 10kB 24.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 20kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 30kB 12.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 40kB 10.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 3.8MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# (Solo per Google Colab)\n",
    "%tensorflow_version 2.x\n",
    "!pip install -q keras==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cravARp7zGCj"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.applications import mobilenet_v2, ResNet50, InceptionV3\n",
    "from tensorflow.keras.preprocessing import image as kimage\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgylhD0s0_SO"
   },
   "source": [
    "# Data Loader E6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "NLIebkZ9zqxF",
    "outputId": "a3b52ff9-5871-434f-9b05-6d4fded5f9ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-29 13:29:29--  https://www.dropbox.com/s/drwy7fq5svwv78p/101_ObjectCategories_split.tar\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.67.1, 2620:100:6023:1::a27d:4301\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.67.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/drwy7fq5svwv78p/101_ObjectCategories_split.tar [following]\n",
      "--2020-08-29 13:29:29--  https://www.dropbox.com/s/raw/drwy7fq5svwv78p/101_ObjectCategories_split.tar\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc0f28c7157d6814fe3171268675.dl.dropboxusercontent.com/cd/0/inline/A-bQmGqY5nHTNW-SAf_1GXBexX4ZcFWaX1DLR-vMd62AWBDA9NOOY0fFg_SsaJ2b-HumR-7OZJqEoFQxKo11iCS5AiUkSVv-wuZ8KznkAKR4p-wjpMYg_lddCCD8hmcBmqs/file# [following]\n",
      "--2020-08-29 13:29:29--  https://uc0f28c7157d6814fe3171268675.dl.dropboxusercontent.com/cd/0/inline/A-bQmGqY5nHTNW-SAf_1GXBexX4ZcFWaX1DLR-vMd62AWBDA9NOOY0fFg_SsaJ2b-HumR-7OZJqEoFQxKo11iCS5AiUkSVv-wuZ8KznkAKR4p-wjpMYg_lddCCD8hmcBmqs/file\n",
      "Resolving uc0f28c7157d6814fe3171268675.dl.dropboxusercontent.com (uc0f28c7157d6814fe3171268675.dl.dropboxusercontent.com)... 162.125.67.15, 2620:100:6023:15::a27d:430f\n",
      "Connecting to uc0f28c7157d6814fe3171268675.dl.dropboxusercontent.com (uc0f28c7157d6814fe3171268675.dl.dropboxusercontent.com)|162.125.67.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/A-aegaEK6U31wHs81qJEjGeaCQfAL3uk1GtLOhhCTYjNRZxpZj3INaW9mkfrhwXVdzyveSsFQHCa91k5SuMNORkMdYsI8cex7OKbJNqvXeXAg4bbGab8RRhXL4INnvoj7sJO8kuf5WxzlmSU08HlRrQC7OfQfJwyOxB2pqwiFHZ2xleF4uMdQj8CESvnpO60rdR1B-UuHy0B9f_g-t_NceP7Y-Z0ItRvcQNyH_72s32Y46QhplOlZfj-B3gEFQiPKLPRoiAcdH3pBTHop61fWKjG_jVbuaX5O9PxZPlto-1wQB_vOvI2JxxZ2ufHIaMon3fCGkeP-f9j7jK2sdt21kkYXU1kmJqYIQYfWg4UXYrlKg/file [following]\n",
      "--2020-08-29 13:29:30--  https://uc0f28c7157d6814fe3171268675.dl.dropboxusercontent.com/cd/0/inline2/A-aegaEK6U31wHs81qJEjGeaCQfAL3uk1GtLOhhCTYjNRZxpZj3INaW9mkfrhwXVdzyveSsFQHCa91k5SuMNORkMdYsI8cex7OKbJNqvXeXAg4bbGab8RRhXL4INnvoj7sJO8kuf5WxzlmSU08HlRrQC7OfQfJwyOxB2pqwiFHZ2xleF4uMdQj8CESvnpO60rdR1B-UuHy0B9f_g-t_NceP7Y-Z0ItRvcQNyH_72s32Y46QhplOlZfj-B3gEFQiPKLPRoiAcdH3pBTHop61fWKjG_jVbuaX5O9PxZPlto-1wQB_vOvI2JxxZ2ufHIaMon3fCGkeP-f9j7jK2sdt21kkYXU1kmJqYIQYfWg4UXYrlKg/file\n",
      "Reusing existing connection to uc0f28c7157d6814fe3171268675.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 145737728 (139M) [application/x-tar]\n",
      "Saving to: ‘101_ObjectCategories_split.tar’\n",
      "\n",
      "101_ObjectCategorie 100%[===================>] 138.99M  17.8MB/s    in 7.7s    \n",
      "\n",
      "2020-08-29 13:29:38 (18.0 MB/s) - ‘101_ObjectCategories_split.tar’ saved [145737728/145737728]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# Download del dataset tramite wget\n",
    "!wget https://www.dropbox.com/s/drwy7fq5svwv78p/101_ObjectCategories_split.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "099fxq860tR8"
   },
   "outputs": [],
   "source": [
    "# Estrazione file e rimozione archivio\n",
    "import tarfile\n",
    "tar = tarfile.open('101_ObjectCategories_split.tar')\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "!rm 101_ObjectCategories_split.tar\n",
    "base_path = '101_ObjectCategories_split/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Aoi9IqSv02B8",
    "outputId": "cb5cb7ea-14d7-4ff3-87fc-97e8877c6640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4600 images belonging to 102 classes.\n",
      "Found 4600 images belonging to 102 classes.\n",
      "Found 4544 images belonging to 102 classes.\n",
      "Found 4544 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "# Trasformazioni da applicare\n",
    "train_processing_res = kimage.ImageDataGenerator(preprocessing_function=tensorflow.keras.applications.resnet.preprocess_input)\n",
    "train_processing_inc = kimage.ImageDataGenerator(preprocessing_function=tensorflow.keras.applications.inception_v3.preprocess_input)\n",
    "\n",
    "# Informazioni su dove reperire i dati e come dividerli\n",
    "train_generator_res = train_processing_res.flow_from_directory(\n",
    "        directory=base_path+'train',\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "        seed=1\n",
    ")\n",
    "train_generator_inc = train_processing_inc.flow_from_directory(\n",
    "        directory=base_path+'train',\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "        seed=1\n",
    ")\n",
    "\n",
    "# test\n",
    "test_processing_res = kimage.ImageDataGenerator(preprocessing_function=tensorflow.keras.applications.resnet.preprocess_input)\n",
    "test_generator_res = test_processing_res.flow_from_directory(\n",
    "        directory=base_path+'test',\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True\n",
    ")\n",
    "test_processing_inc = kimage.ImageDataGenerator(preprocessing_function=tensorflow.keras.applications.inception_v3.preprocess_input)\n",
    "test_generator_inc = test_processing_inc.flow_from_directory(\n",
    "        directory=base_path+'test',\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsvPXZ-k1jtA"
   },
   "source": [
    "# ResNet50 vs InceptionV3 Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50\n",
    "ResNet50 è una CNN a 50 strati. Apparentemente rendere i modelli più profondi è il metodo basilare per migliorare la performance o affrontare problemi più complessi, ma come per i percettroni agli albori degli studi nel campo, è difficile allenare modelli all'aumentare degli strati, in particolare perché i gradienti nella backpropagation \"svaniscono\" ed i pesi negli strati iniziali vengono modificati troppo poco. \n",
    "ResNet è organizzata a blocchi in cui viene approssimata non la funzione obiettivo ideale, bensì quella residuale, al netto degli input del blocco. In questo modo ogni blocco ha dei gradienti utili.\n",
    "\n",
    "## InceptionV3\n",
    "InceptionV3 è una versione della rete Inception, in cui moduli analoghi locali con struttura interna parallela, e di comprovata efficacia, vengono riprodotti in serie. Dei classificatori ausiliari biforcano lungo la serie, in modo da iniettare gradienti significativi anche per i moduli a monte della serie stessa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3IL4xn5U1ipb"
   },
   "outputs": [],
   "source": [
    "# Modelli di base\n",
    "res_base_net = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False, pooling='avg')\n",
    "inc_base_net = InceptionV3(input_shape=(224,224,3), weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Pw5V5xm2h3n"
   },
   "outputs": [],
   "source": [
    "# Congelamento del modello di base (solo per fine-tuning)\n",
    "for modello in (res_base_net, inc_base_net):\n",
    "  for layer in modello.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Output del modello di base (Res, poi Inc)\n",
    "x = res_base_net.output\n",
    "# Nuovo livello fully-connected intermedio + ReLU\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# Nuovo livello fully-connected finale + softmax\n",
    "pred_res = Dense(102, activation='softmax')(x)\n",
    "# Inc\n",
    "y = inc_base_net.output\n",
    "y = Dense(1024, activation='relu')(y)\n",
    "pred_inc = Dense(102, activation='softmax')(y)\n",
    "\n",
    "# Modelli specializzato\n",
    "resnet = Model(inputs=res_base_net.input, outputs=pred_res)\n",
    "incnet = Model(inputs=inc_base_net.input, outputs=pred_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPjdfRrz39Hv"
   },
   "outputs": [],
   "source": [
    "# Compila il modello per l'addestramento\n",
    "resnet.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "            optimizer=optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "incnet.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "            optimizer=optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "ctIwj5Qw4GKC",
    "outputId": "2a33908a-44d8-498b-8814-80685defbfe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "144/144 [==============================] - 68s 470ms/step - loss: 1.3302 - accuracy: 0.7213 - val_loss: 0.6482 - val_accuracy: 0.8294\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 67s 462ms/step - loss: 0.2800 - accuracy: 0.9204 - val_loss: 0.4457 - val_accuracy: 0.8805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbad3ab9588>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.fit(train_generator_res, epochs=2, validation_data=test_generator_res, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "CA7Fb8wy4PYA",
    "outputId": "4d0ea524-397b-4805-ccb7-f2670179cee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "144/144 [==============================] - 49s 337ms/step - loss: 0.3850 - accuracy: 0.9022 - val_loss: 0.6479 - val_accuracy: 0.8565\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 47s 327ms/step - loss: 0.2023 - accuracy: 0.9411 - val_loss: 0.5324 - val_accuracy: 0.8754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbad38df748>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incnet.fit(train_generator_inc, epochs=2, validation_data=test_generator_inc, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26ugElyNb9yV"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Data Augmentation è l'operazione che aumenta i samples di training applicando diverse trasformazioni ai dati originali, in modo da sopperire al numero relativamente esiguo e soprattutto alla varianza ridotta rispetto al contesto reale o di test in cui si vuole far funzionare il modello. Rotazioni, trasformazioni speculari, variazioni luminose e cromatiche servono a rendere la variabilità del training set (un sampling ridotto e anche distorto della realtà) più simile a quella del \"mondo esterno\" del deployment di modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "XoC2XFAl4Vgt",
    "outputId": "ba71f86a-17e8-4a0b-ec37-6ad1147d7e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4600 images belonging to 102 classes.\n",
      "Found 4600 images belonging to 102 classes.\n",
      "Found 4544 images belonging to 102 classes.\n",
      "Found 4544 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing con augmentation\n",
    "data_aug_res = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=60,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    brightness_range=[0.67, 1.33],\n",
    "    zoom_range=[0.67, 1.33],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    preprocessing_function=tensorflow.keras.applications.resnet.preprocess_input,\n",
    "    validation_split=0.0\n",
    ")\n",
    "data_aug_inc = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=60,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    brightness_range=[0.67, 1.33],\n",
    "    zoom_range=[0.67, 1.33],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    preprocessing_function=tensorflow.keras.applications.inception_v3.preprocess_input,\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "# train\n",
    "train_generator_aug_res = data_aug_res.flow_from_directory(\n",
    "        directory=base_path+'train',\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "        seed=1\n",
    ")\n",
    "train_generator_aug_inc = data_aug_inc.flow_from_directory(\n",
    "        directory=base_path+'train',\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "        seed=1\n",
    ")\n",
    "\n",
    "# test\n",
    "test_generator_aug_res = data_aug_res.flow_from_directory(\n",
    "        directory=base_path+'test',\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True\n",
    ")\n",
    "test_generator_aug_inc = data_aug_inc.flow_from_directory(\n",
    "        directory=base_path+'test',\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loOPU2cqiBn3"
   },
   "outputs": [],
   "source": [
    "# Ricompila il modello per l'addestramento\n",
    "resnet.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "            optimizer=optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "incnet.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "            optimizer=optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "0rok6A3eiTsA",
    "outputId": "33189235-e367-421e-c042-cd85480d0746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "144/144 [==============================] - 165s 1s/step - loss: 0.3742 - accuracy: 0.9080 - val_loss: 1.1946 - val_accuracy: 0.8030\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 164s 1s/step - loss: 0.2964 - accuracy: 0.9207 - val_loss: 1.2765 - val_accuracy: 0.8105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbacd1c8ba8>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.fit(train_generator_aug_res, epochs=2, validation_data=test_generator_aug_res, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "N1Tqs_FJiw0A",
    "outputId": "abfa3e6a-85a1-40f3-9a4c-afd2edfd2f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "144/144 [==============================] - 157s 1s/step - loss: 0.7729 - accuracy: 0.8089 - val_loss: 1.1534 - val_accuracy: 0.7531\n",
      "Epoch 2/2\n",
      "144/144 [==============================] - 156s 1s/step - loss: 0.6624 - accuracy: 0.8276 - val_loss: 1.0680 - val_accuracy: 0.7663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbacb0eea58>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incnet.fit(train_generator_aug_inc, epochs=2, validation_data=test_generator_aug_inc, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jkhmIfNmGXr"
   },
   "source": [
    "Si nota un apprendimento possibilmente rallentato, ma una generalizzazione meno distante dalla performance di training. Vale la pena aumentare il numero di epoche di training ed esaminare i risultati di validation quando l'adattamento al training set sembra simile a quanto visto prima della data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "xDFiBVtoi1Y2",
    "outputId": "c0b4e520-6a8c-455b-f084-cc073930857b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "144/144 [==============================] - 166s 1s/step - loss: 0.2733 - accuracy: 0.9324 - val_loss: 1.2263 - val_accuracy: 0.8063\n",
      "Epoch 2/10\n",
      "144/144 [==============================] - 164s 1s/step - loss: 0.2825 - accuracy: 0.9326 - val_loss: 1.2551 - val_accuracy: 0.8072\n",
      "Epoch 3/10\n",
      "144/144 [==============================] - 165s 1s/step - loss: 0.3076 - accuracy: 0.9291 - val_loss: 1.3963 - val_accuracy: 0.8050\n",
      "Epoch 4/10\n",
      "144/144 [==============================] - 163s 1s/step - loss: 0.2655 - accuracy: 0.9361 - val_loss: 1.6155 - val_accuracy: 0.7980\n",
      "Epoch 5/10\n",
      "144/144 [==============================] - 166s 1s/step - loss: 0.3069 - accuracy: 0.9324 - val_loss: 1.3697 - val_accuracy: 0.8160\n",
      "Epoch 6/10\n",
      "144/144 [==============================] - 164s 1s/step - loss: 0.2789 - accuracy: 0.9339 - val_loss: 1.4803 - val_accuracy: 0.8193\n",
      "Epoch 7/10\n",
      "144/144 [==============================] - 164s 1s/step - loss: 0.3189 - accuracy: 0.9339 - val_loss: 1.5926 - val_accuracy: 0.8046\n",
      "Epoch 8/10\n",
      "144/144 [==============================] - 165s 1s/step - loss: 0.2612 - accuracy: 0.9398 - val_loss: 1.5926 - val_accuracy: 0.8055\n",
      "Epoch 9/10\n",
      "144/144 [==============================] - 165s 1s/step - loss: 0.2520 - accuracy: 0.9426 - val_loss: 1.4643 - val_accuracy: 0.8145\n",
      "Epoch 10/10\n",
      "144/144 [==============================] - 165s 1s/step - loss: 0.2602 - accuracy: 0.9417 - val_loss: 1.4651 - val_accuracy: 0.8118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbac7ee3fd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.fit(train_generator_aug_res, epochs=10, validation_data=test_generator_aug_res, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "s94eG9mkmnBU",
    "outputId": "300d6bac-552a-440d-f41a-6567d86158c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "144/144 [==============================] - 155s 1s/step - loss: 0.6794 - accuracy: 0.8220 - val_loss: 1.2815 - val_accuracy: 0.7458\n",
      "Epoch 2/10\n",
      "144/144 [==============================] - 155s 1s/step - loss: 0.6684 - accuracy: 0.8304 - val_loss: 1.1007 - val_accuracy: 0.7487\n",
      "Epoch 3/10\n",
      "144/144 [==============================] - 155s 1s/step - loss: 0.6430 - accuracy: 0.8361 - val_loss: 1.1067 - val_accuracy: 0.7641\n",
      "Epoch 4/10\n",
      "144/144 [==============================] - 155s 1s/step - loss: 0.6709 - accuracy: 0.8293 - val_loss: 1.1916 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "144/144 [==============================] - 155s 1s/step - loss: 0.6471 - accuracy: 0.8311 - val_loss: 1.1568 - val_accuracy: 0.7691\n",
      "Epoch 6/10\n",
      "144/144 [==============================] - 155s 1s/step - loss: 0.5987 - accuracy: 0.8448 - val_loss: 1.2660 - val_accuracy: 0.7577\n",
      "Epoch 7/10\n",
      "144/144 [==============================] - 155s 1s/step - loss: 0.6408 - accuracy: 0.8352 - val_loss: 1.1653 - val_accuracy: 0.7711\n",
      "Epoch 8/10\n",
      "144/144 [==============================] - 155s 1s/step - loss: 0.6147 - accuracy: 0.8439 - val_loss: 1.2138 - val_accuracy: 0.7520\n",
      "Epoch 9/10\n",
      "144/144 [==============================] - 156s 1s/step - loss: 0.5764 - accuracy: 0.8530 - val_loss: 1.3286 - val_accuracy: 0.7469\n",
      "Epoch 10/10\n",
      "144/144 [==============================] - 157s 1s/step - loss: 0.6001 - accuracy: 0.8472 - val_loss: 1.1277 - val_accuracy: 0.7742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbac720efd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incnet.fit(train_generator_aug_inc, epochs=10, validation_data=test_generator_aug_inc, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7kq5qinDWCE"
   },
   "source": [
    "# Relazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucwnfi7FDYsQ"
   },
   "source": [
    "Le due architetture selezionate come base per un classificatore denso, ResNet50 ed InceptionV3, sono piuttosto differenti per dimensioni e struttura, dando luogo a risultati diversi sul validation set. InceptionV3, seppur più complesso, non outperforma ResNet50 a parità di MLP a valle e dataset su cui sono stati allenati i pesi.\n",
    "La data augmentation tentata ha compreso la rotazione, l'inversione speculare, la traslazione, lo zoom e i cambi di luminosità per i sample. L'insieme di trasformazioni è probabilmente difficile da gestire per il training dei layer densi, ed i risultati potrebbero migliorare permettendo anche ai pesi dei layer trasferiti (sempre inizializzati con i valori allenati su ImageNet) di variare."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "E6_tshimanga_fabrice_847529.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
